{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"gpuClass":"standard","accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":471606,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":380237,"modelId":399994},{"sourceId":471887,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":380432,"modelId":400156}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 載入函式庫\n","metadata":{"id":"S9NTZ1VEtbV7"}},{"cell_type":"code","source":"import os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nimport numpy as np","metadata":{"id":"vCvF-fM0tfsq","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:21.670284Z","iopub.execute_input":"2025-07-15T06:13:21.671023Z","iopub.status.idle":"2025-07-15T06:13:31.610708Z","shell.execute_reply.started":"2025-07-15T06:13:21.670987Z","shell.execute_reply":"2025-07-15T06:13:31.610091Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/vgg/pytorch/default/1')\nfrom vgg import vgg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:31.611985Z","iopub.execute_input":"2025-07-15T06:13:31.612365Z","iopub.status.idle":"2025-07-15T06:13:31.621383Z","shell.execute_reply.started":"2025-07-15T06:13:31.612343Z","shell.execute_reply":"2025-07-15T06:13:31.620835Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 超參數設定","metadata":{"id":"_X_r4dtMuwbh"}},{"cell_type":"code","source":"DATASET = 'cifar10'\nTEST_BATCH_SIZE = 1000\nCUDA = True\nPRUNE_PERCENT = 0.5 # Change your prune ratio!\nWEIGHT_PATH = '/kaggle/input/weight_path/pytorch/default/1/model_best_lambda_0.0001.pth'\nPRUNE_PATH = f'/kaggle/working/model_prune_ratio_{PRUNE_PERCENT}.pth'","metadata":{"id":"_2NkY0LyuyQh","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:31.622029Z","iopub.execute_input":"2025-07-15T06:13:31.622300Z","iopub.status.idle":"2025-07-15T06:13:31.643681Z","shell.execute_reply.started":"2025-07-15T06:13:31.622280Z","shell.execute_reply":"2025-07-15T06:13:31.642681Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 測試函數(觀察模型精確度)","metadata":{}},{"cell_type":"code","source":"def test(model, prune_ratio):\n    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])),\n        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n    model.eval()\n    correct = 0\n    with torch.no_grad():\n      for data, target in test_loader:\n          if CUDA:\n              data, target = data.cuda(), target.cuda()\n          data, target = Variable(data), Variable(target)\n          output = model(data)\n          pred = output.data.max(1, keepdim=True)[1]\n          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print('\\nTest set [prune_ratio={}] Accuracy: {}/{} ({:.1f}%)\\n'.format(\n        prune_ratio, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:31.645513Z","iopub.execute_input":"2025-07-15T06:13:31.645951Z","iopub.status.idle":"2025-07-15T06:13:31.662444Z","shell.execute_reply.started":"2025-07-15T06:13:31.645931Z","shell.execute_reply":"2025-07-15T06:13:31.661704Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 載入模型","metadata":{"id":"L7z4dkhJwB4Z"}},{"cell_type":"code","source":"CUDA = CUDA and torch.cuda.is_available()\n\nmodel = vgg()\nif CUDA:\n    model.cuda()\n\nif WEIGHT_PATH:\n    if os.path.isfile(WEIGHT_PATH):\n        checkpoint = torch.load(WEIGHT_PATH)\n        best_prec1 = checkpoint['best_prec1']\n        model.load_state_dict(checkpoint['state_dict'])\n        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n\n    else:\n        print(\"NO CHECKPOINT FOUND\")\n\nprint(model)","metadata":{"id":"lpIqnhfKwEcJ","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:31.663246Z","iopub.execute_input":"2025-07-15T06:13:31.663479Z","iopub.status.idle":"2025-07-15T06:13:33.474176Z","shell.execute_reply.started":"2025-07-15T06:13:31.663456Z","shell.execute_reply":"2025-07-15T06:13:33.473470Z"}},"outputs":[{"name":"stdout","text":"LOADING CHECKPOINT /kaggle/input/weight_path/pytorch/default/1/model_best_lambda_0.0001.pth @EPOCH=52, BEST_PREC1=0.9243999719619751\nvgg(\n  (feature): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n  )\n  (classifier): Linear(in_features=512, out_features=10, bias=True)\n)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 進行剪枝\n#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n#### 利用PRUNE_RATIO中取得閥值","metadata":{"id":"srauYOD-1vSp"}},{"cell_type":"code","source":"total = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        total += m.weight.data.shape[0]\n\nbn = torch.zeros(total)\nindex = 0\nfor m in model.modules():\n    if isinstance(m, nn.BatchNorm2d):\n        size = m.weight.data.shape[0]\n        bn[index:(index+size)] = m.weight.data.abs().clone()\n        index += size\n\ny, i = torch.sort(bn)\n\n\nthreshold_index = int(total * PRUNE_PERCENT)\nthreshold = y[threshold_index]\n","metadata":{"id":"xgtUBaDw1uuR","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:33.474933Z","iopub.execute_input":"2025-07-15T06:13:33.475207Z","iopub.status.idle":"2025-07-15T06:13:33.518998Z","shell.execute_reply.started":"2025-07-15T06:13:33.475186Z","shell.execute_reply":"2025-07-15T06:13:33.518432Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 建立CONFIG，之後建立剪枝後網路時需要用到此CONFIG","metadata":{"id":"1sy0JNTN-h3B"}},{"cell_type":"code","source":"pruned = 0\ncfg = []  #用來建立剪枝網路的CONFIG\ncfg_mask = [] #用來幫助剪枝的遮罩","metadata":{"id":"PBklaqUZHnvp","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:33.519684Z","iopub.execute_input":"2025-07-15T06:13:33.519888Z","iopub.status.idle":"2025-07-15T06:13:33.523441Z","shell.execute_reply.started":"2025-07-15T06:13:33.519873Z","shell.execute_reply":"2025-07-15T06:13:33.522923Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 根據Batch Normalization Layer資訊建立CONFIG\n#### 1.複製Batch Normalization Layer的weight(也就是scale factor)\n#### 2.建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n#### 3.大於threshold的index的值加總後，會是剪枝後Layer對應的輸出channel\n#### 4.最後得到要建立剪枝模型的CONFIG","metadata":{"id":"66vDWd5BMmph"}},{"cell_type":"code","source":"for k, m in enumerate(model.modules()):\n    if isinstance(m, nn.BatchNorm2d):\n        weight_copy = m.weight.data.clone()\n        mask = weight_copy.abs().gt(threshold).float().cuda()\n\n        # Deal with the case where there's no channel, at least 3 channels should be kept\n        num_channels = int(torch.sum(mask))\n        if num_channels < 3:\n            _, indices = torch.topk(weight_copy.abs(), 3)   # choose the top 3 channels\n            mask = torch.zeros_like(mask)\n            mask[indices] = 1.0\n            num_channels = 3\n\n        pruned = pruned + mask.shape[0] - torch.sum(mask)\n        cfg.append(int(torch.sum(mask)))\n        cfg_mask.append(mask.clone())\n        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n            format(k, mask.shape[0], int(torch.sum(mask))))\n    elif isinstance(m, nn.MaxPool2d):\n        cfg.append('M')\n\npruned_ratio = pruned/total\n\nprint(f'PRUNE RATIO={pruned_ratio}')\nprint('PREPROCESSING SUCCESSFUL!')\n\nprint(cfg)\n","metadata":{"id":"10ilGgoZ1SR1","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:33.524097Z","iopub.execute_input":"2025-07-15T06:13:33.524343Z","iopub.status.idle":"2025-07-15T06:13:33.818207Z","shell.execute_reply.started":"2025-07-15T06:13:33.524321Z","shell.execute_reply":"2025-07-15T06:13:33.817402Z"}},"outputs":[{"name":"stdout","text":"layer index: 3 \t total channel: 64 \t remaining channel: 23\nlayer index: 6 \t total channel: 64 \t remaining channel: 63\nlayer index: 10 \t total channel: 128 \t remaining channel: 84\nlayer index: 13 \t total channel: 128 \t remaining channel: 121\nlayer index: 17 \t total channel: 256 \t remaining channel: 129\nlayer index: 20 \t total channel: 256 \t remaining channel: 67\nlayer index: 23 \t total channel: 256 \t remaining channel: 9\nlayer index: 26 \t total channel: 256 \t remaining channel: 3\nlayer index: 30 \t total channel: 512 \t remaining channel: 3\nlayer index: 33 \t total channel: 512 \t remaining channel: 3\nlayer index: 36 \t total channel: 512 \t remaining channel: 3\nlayer index: 39 \t total channel: 512 \t remaining channel: 3\nlayer index: 43 \t total channel: 512 \t remaining channel: 3\nlayer index: 46 \t total channel: 512 \t remaining channel: 3\nlayer index: 49 \t total channel: 512 \t remaining channel: 3\nlayer index: 52 \t total channel: 512 \t remaining channel: 54\nPRUNE RATIO=0.8957121968269348\nPREPROCESSING SUCCESSFUL!\n[23, 63, 'M', 84, 121, 'M', 129, 67, 9, 3, 'M', 3, 3, 3, 3, 'M', 3, 3, 3, 54]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 建立剪枝模型","metadata":{"id":"_ha2BuBl1ifM"}},{"cell_type":"code","source":"newmodel = vgg(cfg=cfg)\nnewmodel.cuda()","metadata":{"id":"SlWNdj2f1nWs","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:13:33.819328Z","iopub.execute_input":"2025-07-15T06:13:33.819582Z","iopub.status.idle":"2025-07-15T06:13:33.839729Z","shell.execute_reply.started":"2025-07-15T06:13:33.819563Z","shell.execute_reply":"2025-07-15T06:13:33.839146Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"vgg(\n  (feature): Sequential(\n    (0): Conv2d(3, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(23, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(63, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (8): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(84, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (11): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(121, 129, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (15): BatchNorm2d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(129, 67, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (18): BatchNorm2d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(67, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (21): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (24): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (28): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (31): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (34): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (37): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (41): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (44): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (47): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(3, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (50): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n  )\n  (classifier): Linear(in_features=54, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### 將原本的模型權重複製到剪枝的模型\n#### 1.決定該層的輸入與輸出Channel\n#### 2.根據不同層決定要複製什麼權重\n###### Batch Normalization Layer\n1.   scale factor\n2.   bias\n3.   running mean\n4.   running variance\n\n###### Convolutional Layer\n1.   weight\n2.   bias\n\n###### Linear Layer\n1.   weight\n2.   bias\n\n","metadata":{"id":"ms9Usgkh1Vbe"}},{"cell_type":"code","source":"layer_id_in_cfg = 0\nstart_mask = torch.ones(3)  # 3 為input channel(R,G,B)\nend_mask = cfg_mask[layer_id_in_cfg]\ncount = 0\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.BatchNorm2d):\n\n        # 處理剪枝後的權重\n        m0.weight.data.mul_(end_mask)\n        m0.bias.data.mul_(end_mask)\n\n        # 找出遮罩中非零元素的index\n        idx = torch.nonzero(end_mask, as_tuple=False).squeeze().cuda()\n\n        # 將原本模型的權重複製到剪枝模型的權重\n\n        # 複製weight與bias\n        m1.weight.data.copy_(m0.weight.data[idx].clone())\n        m1.bias.data.copy_(m0.bias.data[idx].clone())\n\n        # 複製running mean跟running variance\n        m1.running_mean.copy_(m0.running_mean[idx].clone())\n        m1.running_var.copy_(m0.running_var[idx].clone())\n\n        layer_id_in_cfg += 1\n        start_mask = end_mask.clone()\n\n        #最後一層連接層不做修改\n        if layer_id_in_cfg < len(cfg_mask):\n            end_mask = cfg_mask[layer_id_in_cfg]\n    elif isinstance(m0, nn.Conv2d):\n        # 將原本模型的捲積層權重複製到對應剪枝模型卷積層的權重\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n\n        w = m0.weight.data[:, idx0, :, :].clone()\n        w = w[idx1, :, :, :].clone()\n        m1.weight.data = w.clone()\n        if m0.bias is not None:\n            # 如果有bias，則複製bias\n            m1.bias.data = m0.bias.data[idx1].clone()\n    elif isinstance(m0, nn.Linear):\n        # 參考 https://pytorch.org/docs/stable/generated/torch.nn.Linear.html 來決定該如何複製Linear Layer參數\n\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n\n        # 複製weight\n        m1.weight.data.copy_(m0.weight.data[:, idx0].clone())\n\n        # 複製bias\n        if m0.bias is not None:\n            m1.bias.data.copy_(m0.bias.data.clone())\n\n","metadata":{"id":"hQcKuMDee46V","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:14:00.743355Z","iopub.execute_input":"2025-07-15T06:14:00.743633Z","iopub.status.idle":"2025-07-15T06:14:00.787380Z","shell.execute_reply.started":"2025-07-15T06:14:00.743613Z","shell.execute_reply":"2025-07-15T06:14:00.786415Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"#### 儲存模型並印出結果\n","metadata":{"id":"AFkMmFLo88mc"}},{"cell_type":"code","source":"torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n\nprint(f'PRUNED MODEL SAVED TO {PRUNE_PATH}')\nprint(newmodel)\nmodel = newmodel\ntest(newmodel, PRUNE_PERCENT)","metadata":{"id":"cuo3HXHt9Ar-","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:14:04.642420Z","iopub.execute_input":"2025-07-15T06:14:04.643306Z","iopub.status.idle":"2025-07-15T06:14:14.397210Z","shell.execute_reply.started":"2025-07-15T06:14:04.643278Z","shell.execute_reply":"2025-07-15T06:14:14.396305Z"}},"outputs":[{"name":"stdout","text":"PRUNED MODEL SAVED TO /kaggle/working/model_prune_ratio_0.9.pth\nvgg(\n  (feature): Sequential(\n    (0): Conv2d(3, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(23, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(63, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (8): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(84, 121, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (11): BatchNorm2d(121, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(121, 129, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (15): BatchNorm2d(129, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(129, 67, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (18): BatchNorm2d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(67, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (21): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (24): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (28): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (31): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (34): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (37): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (41): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (44): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (47): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(3, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (50): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n  )\n  (classifier): Linear(in_features=54, out_features=10, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:03<00:00, 43.8MB/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set [prune_ratio=0.9] Accuracy: 1000/10000 (10.0%)\n\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor(0.1000)"},"metadata":{}}],"execution_count":12}]}