{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":477776,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":384168,"modelId":403551}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install torchinfo\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom torchinfo import summary\nfrom tqdm import tqdm\nimport sys\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:29.802856Z","iopub.execute_input":"2025-07-20T07:24:29.803120Z","iopub.status.idle":"2025-07-20T07:24:41.219289Z","shell.execute_reply.started":"2025-07-20T07:24:29.803098Z","shell.execute_reply":"2025-07-20T07:24:41.218681Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"torch.manual_seed(0)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.backends.cudnn.benchmark = True","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:41.220327Z","iopub.execute_input":"2025-07-20T07:24:41.220702Z","iopub.status.idle":"2025-07-20T07:24:41.322918Z","shell.execute_reply.started":"2025-07-20T07:24:41.220652Z","shell.execute_reply":"2025-07-20T07:24:41.322346Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Download dataset","metadata":{}},{"cell_type":"code","source":"validation_split = 0.2\nbatch_size = 128\n\n# data augmentation and normalization\ntransform_train = transforms.Compose([\n                    transforms.RandomCrop(32, padding=4),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n\ntransform_test = transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n# download dataset\ntrain_and_val_dataset = torchvision.datasets.CIFAR10(\n    root='dataset/',\n    train=True,\n    transform=transform_train,\n    download=True\n)\n\ntest_dataset = torchvision.datasets.CIFAR10(\n    root='dataset/',\n    train=False,\n    transform=transform_test,\n    download=True\n)\n\n# split train and validation dataset\ntrain_size = int((1 - validation_split) * len(train_and_val_dataset))\nval_size = len(train_and_val_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_and_val_dataset, [train_size, val_size])\n\n# create dataLoader\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\ntest_num = len(test_dataset)\ntest_steps = len(test_loader)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:41.323497Z","iopub.execute_input":"2025-07-20T07:24:41.323717Z","iopub.status.idle":"2025-07-20T07:24:47.535187Z","shell.execute_reply.started":"2025-07-20T07:24:41.323696Z","shell.execute_reply":"2025-07-20T07:24:47.534595Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 59.2MB/s] \n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Create teacher and student models\n","metadata":{}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channel)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channel)\n        self.downsample = downsample\n\n    def forward(self, x):\n        identity = x\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out += identity\n        out = self.relu(out)\n\n        return out","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:47.536520Z","iopub.execute_input":"2025-07-20T07:24:47.536791Z","iopub.status.idle":"2025-07-20T07:24:47.542511Z","shell.execute_reply.started":"2025-07-20T07:24:47.536773Z","shell.execute_reply":"2025-07-20T07:24:47.541955Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class ResNet(nn.Module):\n\n    def __init__(self, block, blocks_num, num_classes=1000):\n        super(ResNet, self).__init__()\n        self.in_channel = 64\n\n        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.in_channel)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n\n    def _make_layer(self, block, channel, block_num, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channel != channel * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(channel * block.expansion))\n\n        layers = []\n        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n        self.in_channel = channel * block.expansion\n\n        for _ in range(1, block_num):\n            layers.append(block(self.in_channel, channel))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ######################################################################################################\n        # 1. Finish the forward pass and return the output layer as well as hidden features.  #\n        # 2. The output layer and hidden features will be used later for distilling.       #\n        # 3. You can refer to the ResNet structure illustration to finish it.           #\n        ####################################################################################################\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        feature1 = self.layer1(x)\n        feature2 = self.layer2(feature1)\n        feature3 = self.layer3(feature2)\n        feature4 = self.layer4(feature3)\n\n        x = self.avgpool(feature4)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x, [feature1, feature2, feature3, feature4]\n\ndef resnet18(num_classes=10):\n    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n\ndef resnet34(num_classes=10):\n    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:47.543204Z","iopub.execute_input":"2025-07-20T07:24:47.543450Z","iopub.status.idle":"2025-07-20T07:24:47.561344Z","shell.execute_reply.started":"2025-07-20T07:24:47.543428Z","shell.execute_reply":"2025-07-20T07:24:47.560704Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Teacher model","metadata":{}},{"cell_type":"code","source":"# Teacher = resnet34(num_classes=10)  # commment out this line if loading trained teacher model\nTeacher = torch.load('/kaggle/input/pre-trained/pytorch/kd/1/Teacher.pt', weights_only=False)  # loading trained teacher model\nTeacher = Teacher.to(device)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:47.562020Z","iopub.execute_input":"2025-07-20T07:24:47.562211Z","iopub.status.idle":"2025-07-20T07:24:48.787904Z","shell.execute_reply.started":"2025-07-20T07:24:47.562191Z","shell.execute_reply":"2025-07-20T07:24:48.787136Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"summary(Teacher)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:48.788746Z","iopub.execute_input":"2025-07-20T07:24:48.788933Z","iopub.status.idle":"2025-07-20T07:24:48.799984Z","shell.execute_reply.started":"2025-07-20T07:24:48.788918Z","shell.execute_reply":"2025-07-20T07:24:48.799318Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nResNet                                   --\n├─Conv2d: 1-1                            1,728\n├─BatchNorm2d: 1-2                       128\n├─ReLU: 1-3                              --\n├─MaxPool2d: 1-4                         --\n├─Sequential: 1-5                        --\n│    └─BasicBlock: 2-1                   --\n│    │    └─Conv2d: 3-1                  36,864\n│    │    └─BatchNorm2d: 3-2             128\n│    │    └─ReLU: 3-3                    --\n│    │    └─Conv2d: 3-4                  36,864\n│    │    └─BatchNorm2d: 3-5             128\n│    └─BasicBlock: 2-2                   --\n│    │    └─Conv2d: 3-6                  36,864\n│    │    └─BatchNorm2d: 3-7             128\n│    │    └─ReLU: 3-8                    --\n│    │    └─Conv2d: 3-9                  36,864\n│    │    └─BatchNorm2d: 3-10            128\n│    └─BasicBlock: 2-3                   --\n│    │    └─Conv2d: 3-11                 36,864\n│    │    └─BatchNorm2d: 3-12            128\n│    │    └─ReLU: 3-13                   --\n│    │    └─Conv2d: 3-14                 36,864\n│    │    └─BatchNorm2d: 3-15            128\n├─Sequential: 1-6                        --\n│    └─BasicBlock: 2-4                   --\n│    │    └─Conv2d: 3-16                 73,728\n│    │    └─BatchNorm2d: 3-17            256\n│    │    └─ReLU: 3-18                   --\n│    │    └─Conv2d: 3-19                 147,456\n│    │    └─BatchNorm2d: 3-20            256\n│    │    └─Sequential: 3-21             8,448\n│    └─BasicBlock: 2-5                   --\n│    │    └─Conv2d: 3-22                 147,456\n│    │    └─BatchNorm2d: 3-23            256\n│    │    └─ReLU: 3-24                   --\n│    │    └─Conv2d: 3-25                 147,456\n│    │    └─BatchNorm2d: 3-26            256\n│    └─BasicBlock: 2-6                   --\n│    │    └─Conv2d: 3-27                 147,456\n│    │    └─BatchNorm2d: 3-28            256\n│    │    └─ReLU: 3-29                   --\n│    │    └─Conv2d: 3-30                 147,456\n│    │    └─BatchNorm2d: 3-31            256\n│    └─BasicBlock: 2-7                   --\n│    │    └─Conv2d: 3-32                 147,456\n│    │    └─BatchNorm2d: 3-33            256\n│    │    └─ReLU: 3-34                   --\n│    │    └─Conv2d: 3-35                 147,456\n│    │    └─BatchNorm2d: 3-36            256\n├─Sequential: 1-7                        --\n│    └─BasicBlock: 2-8                   --\n│    │    └─Conv2d: 3-37                 294,912\n│    │    └─BatchNorm2d: 3-38            512\n│    │    └─ReLU: 3-39                   --\n│    │    └─Conv2d: 3-40                 589,824\n│    │    └─BatchNorm2d: 3-41            512\n│    │    └─Sequential: 3-42             33,280\n│    └─BasicBlock: 2-9                   --\n│    │    └─Conv2d: 3-43                 589,824\n│    │    └─BatchNorm2d: 3-44            512\n│    │    └─ReLU: 3-45                   --\n│    │    └─Conv2d: 3-46                 589,824\n│    │    └─BatchNorm2d: 3-47            512\n│    └─BasicBlock: 2-10                  --\n│    │    └─Conv2d: 3-48                 589,824\n│    │    └─BatchNorm2d: 3-49            512\n│    │    └─ReLU: 3-50                   --\n│    │    └─Conv2d: 3-51                 589,824\n│    │    └─BatchNorm2d: 3-52            512\n│    └─BasicBlock: 2-11                  --\n│    │    └─Conv2d: 3-53                 589,824\n│    │    └─BatchNorm2d: 3-54            512\n│    │    └─ReLU: 3-55                   --\n│    │    └─Conv2d: 3-56                 589,824\n│    │    └─BatchNorm2d: 3-57            512\n│    └─BasicBlock: 2-12                  --\n│    │    └─Conv2d: 3-58                 589,824\n│    │    └─BatchNorm2d: 3-59            512\n│    │    └─ReLU: 3-60                   --\n│    │    └─Conv2d: 3-61                 589,824\n│    │    └─BatchNorm2d: 3-62            512\n│    └─BasicBlock: 2-13                  --\n│    │    └─Conv2d: 3-63                 589,824\n│    │    └─BatchNorm2d: 3-64            512\n│    │    └─ReLU: 3-65                   --\n│    │    └─Conv2d: 3-66                 589,824\n│    │    └─BatchNorm2d: 3-67            512\n├─Sequential: 1-8                        --\n│    └─BasicBlock: 2-14                  --\n│    │    └─Conv2d: 3-68                 1,179,648\n│    │    └─BatchNorm2d: 3-69            1,024\n│    │    └─ReLU: 3-70                   --\n│    │    └─Conv2d: 3-71                 2,359,296\n│    │    └─BatchNorm2d: 3-72            1,024\n│    │    └─Sequential: 3-73             132,096\n│    └─BasicBlock: 2-15                  --\n│    │    └─Conv2d: 3-74                 2,359,296\n│    │    └─BatchNorm2d: 3-75            1,024\n│    │    └─ReLU: 3-76                   --\n│    │    └─Conv2d: 3-77                 2,359,296\n│    │    └─BatchNorm2d: 3-78            1,024\n│    └─BasicBlock: 2-16                  --\n│    │    └─Conv2d: 3-79                 2,359,296\n│    │    └─BatchNorm2d: 3-80            1,024\n│    │    └─ReLU: 3-81                   --\n│    │    └─Conv2d: 3-82                 2,359,296\n│    │    └─BatchNorm2d: 3-83            1,024\n├─AdaptiveAvgPool2d: 1-9                 --\n├─Linear: 1-10                           5,130\n=================================================================\nTotal params: 21,282,122\nTrainable params: 21,282,122\nNon-trainable params: 0\n================================================================="},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Student model","metadata":{}},{"cell_type":"code","source":"# Student = resnet18(num_classes=10)  # commment out this line if loading trained student model\nStudent = torch.load('/kaggle/input/pre-trained/pytorch/kd/1/Student.pt', weights_only=False)  # loading trained student model\nStudent = Student.to(device)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:48.800844Z","iopub.execute_input":"2025-07-20T07:24:48.801073Z","iopub.status.idle":"2025-07-20T07:24:49.254571Z","shell.execute_reply.started":"2025-07-20T07:24:48.801057Z","shell.execute_reply":"2025-07-20T07:24:49.253803Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"summary(Student)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.255392Z","iopub.execute_input":"2025-07-20T07:24:49.255852Z","iopub.status.idle":"2025-07-20T07:24:49.264116Z","shell.execute_reply.started":"2025-07-20T07:24:49.255831Z","shell.execute_reply":"2025-07-20T07:24:49.263540Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nResNet                                   --\n├─Conv2d: 1-1                            1,728\n├─BatchNorm2d: 1-2                       128\n├─ReLU: 1-3                              --\n├─MaxPool2d: 1-4                         --\n├─Sequential: 1-5                        --\n│    └─BasicBlock: 2-1                   --\n│    │    └─Conv2d: 3-1                  36,864\n│    │    └─BatchNorm2d: 3-2             128\n│    │    └─ReLU: 3-3                    --\n│    │    └─Conv2d: 3-4                  36,864\n│    │    └─BatchNorm2d: 3-5             128\n│    └─BasicBlock: 2-2                   --\n│    │    └─Conv2d: 3-6                  36,864\n│    │    └─BatchNorm2d: 3-7             128\n│    │    └─ReLU: 3-8                    --\n│    │    └─Conv2d: 3-9                  36,864\n│    │    └─BatchNorm2d: 3-10            128\n├─Sequential: 1-6                        --\n│    └─BasicBlock: 2-3                   --\n│    │    └─Conv2d: 3-11                 73,728\n│    │    └─BatchNorm2d: 3-12            256\n│    │    └─ReLU: 3-13                   --\n│    │    └─Conv2d: 3-14                 147,456\n│    │    └─BatchNorm2d: 3-15            256\n│    │    └─Sequential: 3-16             8,448\n│    └─BasicBlock: 2-4                   --\n│    │    └─Conv2d: 3-17                 147,456\n│    │    └─BatchNorm2d: 3-18            256\n│    │    └─ReLU: 3-19                   --\n│    │    └─Conv2d: 3-20                 147,456\n│    │    └─BatchNorm2d: 3-21            256\n├─Sequential: 1-7                        --\n│    └─BasicBlock: 2-5                   --\n│    │    └─Conv2d: 3-22                 294,912\n│    │    └─BatchNorm2d: 3-23            512\n│    │    └─ReLU: 3-24                   --\n│    │    └─Conv2d: 3-25                 589,824\n│    │    └─BatchNorm2d: 3-26            512\n│    │    └─Sequential: 3-27             33,280\n│    └─BasicBlock: 2-6                   --\n│    │    └─Conv2d: 3-28                 589,824\n│    │    └─BatchNorm2d: 3-29            512\n│    │    └─ReLU: 3-30                   --\n│    │    └─Conv2d: 3-31                 589,824\n│    │    └─BatchNorm2d: 3-32            512\n├─Sequential: 1-8                        --\n│    └─BasicBlock: 2-7                   --\n│    │    └─Conv2d: 3-33                 1,179,648\n│    │    └─BatchNorm2d: 3-34            1,024\n│    │    └─ReLU: 3-35                   --\n│    │    └─Conv2d: 3-36                 2,359,296\n│    │    └─BatchNorm2d: 3-37            1,024\n│    │    └─Sequential: 3-38             132,096\n│    └─BasicBlock: 2-8                   --\n│    │    └─Conv2d: 3-39                 2,359,296\n│    │    └─BatchNorm2d: 3-40            1,024\n│    │    └─ReLU: 3-41                   --\n│    │    └─Conv2d: 3-42                 2,359,296\n│    │    └─BatchNorm2d: 3-43            1,024\n├─AdaptiveAvgPool2d: 1-9                 --\n├─Linear: 1-10                           5,130\n=================================================================\nTotal params: 11,173,962\nTrainable params: 11,173,962\nNon-trainable params: 0\n================================================================="},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Define testing function","metadata":{}},{"cell_type":"code","source":"def test(model, test_loader ,device, type=None):\n    criterion = nn.CrossEntropyLoss()\n    acc = 0.0\n    test_loss = 0.0\n\n    if type == None:\n        model.eval()\n    elif type == 'distiller':\n        model.eval()\n        model.teacher.eval()\n        model.student.eval()\n    else:\n       raise ValueError(f'Error: only support response-based and feature-based distillation')\n\n    with torch.no_grad():\n        test_bar = tqdm(test_loader, file=sys.stdout)\n        for test_data in test_bar:\n            test_images, test_labels = test_data\n            test_images, test_labels = test_images.to(device), test_labels.to(device)\n            if type == None:\n                outputs, features = model(test_images)\n                loss = criterion(outputs, test_labels)\n            elif type == 'distiller':\n                outputs, loss = model(test_images, test_labels)\n            else:\n                raise ValueError(f'Error: only support response-based and feature-based distillation')\n\n            predict_y = torch.max(outputs, dim=1)[1]\n            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n            test_loss += loss.item()\n            test_bar.desc = \"test\"\n\n    test_accurate = acc / test_num\n    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n    return test_loss / test_steps, test_accurate * 100.","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.266528Z","iopub.execute_input":"2025-07-20T07:24:49.266754Z","iopub.status.idle":"2025-07-20T07:24:49.277276Z","shell.execute_reply.started":"2025-07-20T07:24:49.266734Z","shell.execute_reply":"2025-07-20T07:24:49.276710Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Define distillation fuction","metadata":{}},{"cell_type":"code","source":"#####################################################################\n# Finish the loss function for response-based distillation. #\n#####################################################################\ndef loss_re(student_logits, teacher_logits, labels, T, alpha):\n\n    teacher_logits = torch.clamp(teacher_logits, -10, 10)\n    student_logits = torch.clamp(student_logits, -10, 10)\n    \n    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(student_logits/T, dim=1), F.softmax(teacher_logits/T, dim=1)) * (T*T)\n    hard_loss = nn.CrossEntropyLoss()(student_logits, labels)\n    \n    loss = alpha * soft_loss + (1 - alpha) * hard_loss\n    \n    return loss","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.278052Z","iopub.execute_input":"2025-07-20T07:24:49.278266Z","iopub.status.idle":"2025-07-20T07:24:49.288876Z","shell.execute_reply.started":"2025-07-20T07:24:49.278245Z","shell.execute_reply":"2025-07-20T07:24:49.288195Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Distiller(nn.Module):\n    def __init__(self, teacher, student, type, T, alpha):\n        super(Distiller, self).__init__()\n\n        ########################################\n        # 1. Finish the __init__ method. #\n        ########################################\n\n        self.teacher = teacher\n        self.student = student\n\n        self.T = T\n        self.alpha = alpha\n\n        self.type = type\n\n        self.teacher.train()\n        for param in self.teacher.parameters():\n            param.requires_grad = False\n\n    def forward(self, x, target):\n\n        #####################################\n        # 2. Finish the forward pass. #\n        #####################################\n        teacher_logits, teacher_feature = self.teacher(x)\n        student_logits, student_feature = self.student(x)\n\n        if self.type == 'response':\n            loss_distill = loss_re(student_logits, teacher_logits, target, T=self.T, alpha=self.alpha)\n        elif self.type == 'feature':\n            loss_distill = loss_fe(student_logits, student_feature, teacher_feature, target)\n\n        return student_logits, loss_distill","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.289552Z","iopub.execute_input":"2025-07-20T07:24:49.289757Z","iopub.status.idle":"2025-07-20T07:24:49.304943Z","shell.execute_reply.started":"2025-07-20T07:24:49.289735Z","shell.execute_reply":"2025-07-20T07:24:49.304414Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train_distillation(distiller, student, train_loader, val_loader, epochs, learning_rate, device):\n    ce_loss = nn.CrossEntropyLoss()\n    ###########################\n    # define the optimizer #\n    ###########################\n    optimizer = torch.optim.Adam(distiller.student.parameters(), lr=learning_rate)\n\n    loss = []\n    train_error=[]\n    val_error = []\n    valdation_error = []\n    train_loss = []\n    valdation_loss = []\n    train_accuraacy = []\n    valdation_accuracy= []\n\n    for epoch in range(epochs):\n        distiller.train()\n        distiller.teacher.train()\n        distiller.student.train()\n\n        train_loss = 0.0\n        valid_loss = 0.0\n        train_acc = 0.0\n        valid_acc  = 0.0\n        correct = 0.\n        total = 0.\n        V_correct = 0.\n        V_total = 0.\n        train_bar = tqdm(train_loader, file=sys.stdout)\n        for step, data in enumerate(train_bar):\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n\n            outputs, loss = distiller(images, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * images.size(0)\n            pred = outputs.data.max(1, keepdim=True)[1]\n            result = pred.eq(labels.data.view_as(pred))\n            result = np.squeeze(result.cpu().numpy())\n            correct += np.sum(result)\n            total += images.size(0)\n            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n\n        distiller.eval()\n        distiller.teacher.eval()\n        distiller.student.eval()\n\n        with torch.no_grad():\n            val_bar = tqdm(val_loader, file=sys.stdout)\n            for val_data in val_bar:\n\n                val_images, val_labels = val_data\n                val_images, val_labels = val_images.to(device), val_labels.to(device)\n\n                outputs, loss = distiller(val_images, val_labels)\n\n                valid_loss += loss.item() * val_images.size(0)\n                pred = outputs.max(1, keepdim=True)[1]\n                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n                V_total += val_images.size(0)\n                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n\n        train_loss = train_loss / len(train_loader.dataset)\n        train_error.append(train_loss)\n        valid_loss = valid_loss / len(val_loader.dataset)\n        val_error.append(valid_loss)\n        train_accuraacy.append( correct / total)\n        valdation_accuracy.append(V_correct / V_total)\n\n        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n\n    print('Finished Distilling')","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.305730Z","iopub.execute_input":"2025-07-20T07:24:49.305946Z","iopub.status.idle":"2025-07-20T07:24:49.318908Z","shell.execute_reply.started":"2025-07-20T07:24:49.305927Z","shell.execute_reply":"2025-07-20T07:24:49.318303Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Response-based distillation\n## Find Temparature and alpha","metadata":{}},{"cell_type":"code","source":"# T_list = [1, 2, 5, 10]\n# alpha_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n# results = []\n\n# for T in T_list:\n#     for alpha in alpha_list:\n#         print(f\"\\n==== Training with T={T}, alpha={alpha} ====\")        \n#         Student_re = resnet18(num_classes=10)\n#         Student_re = Student_re.to(device)\n#         distiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\n#         train_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=10, learning_rate=0.001, device=device)\n        \n#         reS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n        \n#         results.append((T, alpha, reS_accuracy, reS_loss))\n\n# best = max(results, key=lambda x: x[2])\n# print(f'\\nBest Group：T={best[0]}, alpha={best[1]}, accuracy={best[2]:.2f}, loss={best[3]:.2f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.319442Z","iopub.execute_input":"2025-07-20T07:24:49.319593Z","iopub.status.idle":"2025-07-20T07:24:49.331258Z","shell.execute_reply.started":"2025-07-20T07:24:49.319581Z","shell.execute_reply":"2025-07-20T07:24:49.330655Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"results = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.331830Z","iopub.execute_input":"2025-07-20T07:24:49.332030Z","iopub.status.idle":"2025-07-20T07:24:49.341874Z","shell.execute_reply.started":"2025-07-20T07:24:49.332016Z","shell.execute_reply":"2025-07-20T07:24:49.341330Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"T=3\nalpha=0.5\n\nprint(f\"\\n==== Training with T={T} , alpha={alpha} ====\")        \nStudent_re = resnet18(num_classes=10)\nStudent_re = Student_re.to(device)\ndistiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\ntrain_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=20, learning_rate=0.001, device=device)\n\nreS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n\nresults.append((T, alpha, reS_accuracy, reS_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:24:49.342525Z","iopub.execute_input":"2025-07-20T07:24:49.342763Z","iopub.status.idle":"2025-07-20T07:49:01.551073Z","shell.execute_reply.started":"2025-07-20T07:24:49.342749Z","shell.execute_reply":"2025-07-20T07:49:01.550524Z"}},"outputs":[{"name":"stdout","text":"\n==== Training with T=3 , alpha=0.5 ====\ntrain epoch[1/20]: 100%|██████████| 313/313 [01:05<00:00,  4.76it/s]\nvalid epoch[1/20]: 100%|██████████| 79/79 [00:09<00:00,  7.92it/s]\n\tTraining Loss: 6.085046 \tValidation Loss: 4.904107\n\tTrain Accuracy: 46.485d% (18594/40000)\tValdation Accuracy: 54.700d% (5470/10000) \ntrain epoch[2/20]: 100%|██████████| 313/313 [01:02<00:00,  5.02it/s]\nvalid epoch[2/20]: 100%|██████████| 79/79 [00:09<00:00,  7.95it/s]\n\tTraining Loss: 4.214075 \tValidation Loss: 3.922541\n\tTrain Accuracy: 64.487d% (25795/40000)\tValdation Accuracy: 63.390d% (6339/10000) \ntrain epoch[3/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[3/20]: 100%|██████████| 79/79 [00:09<00:00,  7.92it/s]\n\tTraining Loss: 3.324904 \tValidation Loss: 3.127667\n\tTrain Accuracy: 72.412d% (28965/40000)\tValdation Accuracy: 72.070d% (7207/10000) \ntrain epoch[4/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[4/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 2.709908 \tValidation Loss: 2.715043\n\tTrain Accuracy: 77.688d% (31075/40000)\tValdation Accuracy: 74.730d% (7473/10000) \ntrain epoch[5/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[5/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 2.344871 \tValidation Loss: 2.193638\n\tTrain Accuracy: 80.677d% (32271/40000)\tValdation Accuracy: 79.100d% (7910/10000) \ntrain epoch[6/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[6/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 2.028237 \tValidation Loss: 2.323338\n\tTrain Accuracy: 83.355d% (33342/40000)\tValdation Accuracy: 78.380d% (7838/10000) \ntrain epoch[7/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[7/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 1.804880 \tValidation Loss: 1.761140\n\tTrain Accuracy: 84.880d% (33952/40000)\tValdation Accuracy: 82.930d% (8293/10000) \ntrain epoch[8/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[8/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 1.613699 \tValidation Loss: 1.687939\n\tTrain Accuracy: 86.420d% (34568/40000)\tValdation Accuracy: 83.650d% (8365/10000) \ntrain epoch[9/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[9/20]: 100%|██████████| 79/79 [00:09<00:00,  7.93it/s]\n\tTraining Loss: 1.462481 \tValidation Loss: 1.811118\n\tTrain Accuracy: 87.698d% (35079/40000)\tValdation Accuracy: 82.080d% (8208/10000) \ntrain epoch[10/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[10/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.344781 \tValidation Loss: 1.339857\n\tTrain Accuracy: 88.680d% (35472/40000)\tValdation Accuracy: 86.030d% (8603/10000) \ntrain epoch[11/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[11/20]: 100%|██████████| 79/79 [00:09<00:00,  7.95it/s]\n\tTraining Loss: 1.220396 \tValidation Loss: 1.494809\n\tTrain Accuracy: 89.743d% (35897/40000)\tValdation Accuracy: 85.200d% (8520/10000) \ntrain epoch[12/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[12/20]: 100%|██████████| 79/79 [00:09<00:00,  7.92it/s]\n\tTraining Loss: 1.132514 \tValidation Loss: 1.369101\n\tTrain Accuracy: 90.478d% (36191/40000)\tValdation Accuracy: 85.900d% (8590/10000) \ntrain epoch[13/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[13/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 1.043514 \tValidation Loss: 1.397210\n\tTrain Accuracy: 91.188d% (36475/40000)\tValdation Accuracy: 85.850d% (8585/10000) \ntrain epoch[14/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[14/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 0.965301 \tValidation Loss: 1.293536\n\tTrain Accuracy: 91.950d% (36780/40000)\tValdation Accuracy: 86.540d% (8654/10000) \ntrain epoch[15/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[15/20]: 100%|██████████| 79/79 [00:09<00:00,  7.91it/s]\n\tTraining Loss: 0.908692 \tValidation Loss: 1.224670\n\tTrain Accuracy: 92.345d% (36938/40000)\tValdation Accuracy: 87.380d% (8738/10000) \ntrain epoch[16/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[16/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 0.838081 \tValidation Loss: 1.244931\n\tTrain Accuracy: 93.105d% (37242/40000)\tValdation Accuracy: 87.750d% (8775/10000) \ntrain epoch[17/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[17/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 0.811594 \tValidation Loss: 1.141171\n\tTrain Accuracy: 93.177d% (37271/40000)\tValdation Accuracy: 87.870d% (8787/10000) \ntrain epoch[18/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[18/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 0.759992 \tValidation Loss: 1.182074\n\tTrain Accuracy: 93.713d% (37485/40000)\tValdation Accuracy: 88.230d% (8823/10000) \ntrain epoch[19/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[19/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 0.709956 \tValidation Loss: 1.133269\n\tTrain Accuracy: 94.410d% (37764/40000)\tValdation Accuracy: 88.180d% (8818/10000) \ntrain epoch[20/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[20/20]: 100%|██████████| 79/79 [00:09<00:00,  8.04it/s]\n\tTraining Loss: 0.673952 \tValidation Loss: 1.030978\n\tTrain Accuracy: 94.505d% (37802/40000)\tValdation Accuracy: 89.160d% (8916/10000) \nFinished Distilling\ntest: 100%|██████████| 79/79 [00:08<00:00,  9.11it/s]\ntest_loss: 1.038  test_accuracy: 89.700\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"T=5\nalpha=0.5\n\nprint(f\"\\n==== Training with T={T} , alpha={alpha} ====\")        \nStudent_re = resnet18(num_classes=10)\nStudent_re = Student_re.to(device)\ndistiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\ntrain_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=20, learning_rate=0.001, device=device)\n\nreS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n\nresults.append((T, alpha, reS_accuracy, reS_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:49:01.551819Z","iopub.execute_input":"2025-07-20T07:49:01.552054Z","iopub.status.idle":"2025-07-20T08:13:08.652768Z","shell.execute_reply.started":"2025-07-20T07:49:01.552035Z","shell.execute_reply":"2025-07-20T08:13:08.652053Z"}},"outputs":[{"name":"stdout","text":"\n==== Training with T=5 , alpha=0.5 ====\ntrain epoch[1/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[1/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 9.886301 \tValidation Loss: 8.018025\n\tTrain Accuracy: 46.295d% (18518/40000)\tValdation Accuracy: 55.290d% (5529/10000) \ntrain epoch[2/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[2/20]: 100%|██████████| 79/79 [00:09<00:00,  7.92it/s]\n\tTraining Loss: 6.703613 \tValidation Loss: 5.762221\n\tTrain Accuracy: 64.130d% (25652/40000)\tValdation Accuracy: 66.630d% (6663/10000) \ntrain epoch[3/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[3/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 5.165975 \tValidation Loss: 6.918826\n\tTrain Accuracy: 72.740d% (29096/40000)\tValdation Accuracy: 62.940d% (6294/10000) \ntrain epoch[4/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[4/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 4.164297 \tValidation Loss: 4.203957\n\tTrain Accuracy: 77.817d% (31127/40000)\tValdation Accuracy: 74.430d% (7443/10000) \ntrain epoch[5/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[5/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 3.511695 \tValidation Loss: 3.682653\n\tTrain Accuracy: 81.040d% (32416/40000)\tValdation Accuracy: 77.760d% (7776/10000) \ntrain epoch[6/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[6/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 2.999648 \tValidation Loss: 3.031688\n\tTrain Accuracy: 83.453d% (33381/40000)\tValdation Accuracy: 80.430d% (8043/10000) \ntrain epoch[7/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[7/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 2.643862 \tValidation Loss: 3.116991\n\tTrain Accuracy: 85.425d% (34170/40000)\tValdation Accuracy: 79.930d% (7993/10000) \ntrain epoch[8/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[8/20]: 100%|██████████| 79/79 [00:09<00:00,  7.95it/s]\n\tTraining Loss: 2.364576 \tValidation Loss: 2.706411\n\tTrain Accuracy: 86.845d% (34738/40000)\tValdation Accuracy: 82.490d% (8249/10000) \ntrain epoch[9/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[9/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 2.170393 \tValidation Loss: 2.084019\n\tTrain Accuracy: 87.795d% (35118/40000)\tValdation Accuracy: 85.120d% (8512/10000) \ntrain epoch[10/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[10/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 1.957732 \tValidation Loss: 2.054428\n\tTrain Accuracy: 88.865d% (35546/40000)\tValdation Accuracy: 85.250d% (8525/10000) \ntrain epoch[11/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[11/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 1.794905 \tValidation Loss: 2.019330\n\tTrain Accuracy: 89.650d% (35860/40000)\tValdation Accuracy: 85.210d% (8521/10000) \ntrain epoch[12/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[12/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 1.658672 \tValidation Loss: 1.904624\n\tTrain Accuracy: 90.385d% (36154/40000)\tValdation Accuracy: 86.390d% (8639/10000) \ntrain epoch[13/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[13/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 1.540013 \tValidation Loss: 1.765407\n\tTrain Accuracy: 91.105d% (36442/40000)\tValdation Accuracy: 87.090d% (8709/10000) \ntrain epoch[14/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[14/20]: 100%|██████████| 79/79 [00:09<00:00,  8.03it/s]\n\tTraining Loss: 1.436681 \tValidation Loss: 1.639082\n\tTrain Accuracy: 91.830d% (36732/40000)\tValdation Accuracy: 87.430d% (8743/10000) \ntrain epoch[15/20]: 100%|██████████| 313/313 [01:01<00:00,  5.07it/s]\nvalid epoch[15/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 1.323094 \tValidation Loss: 1.665192\n\tTrain Accuracy: 92.623d% (37049/40000)\tValdation Accuracy: 87.230d% (8723/10000) \ntrain epoch[16/20]: 100%|██████████| 313/313 [01:01<00:00,  5.07it/s]\nvalid epoch[16/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 1.267234 \tValidation Loss: 1.539115\n\tTrain Accuracy: 92.880d% (37152/40000)\tValdation Accuracy: 88.380d% (8838/10000) \ntrain epoch[17/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[17/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 1.166304 \tValidation Loss: 1.626910\n\tTrain Accuracy: 93.537d% (37415/40000)\tValdation Accuracy: 88.150d% (8815/10000) \ntrain epoch[18/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[18/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 1.128617 \tValidation Loss: 1.438231\n\tTrain Accuracy: 93.843d% (37537/40000)\tValdation Accuracy: 89.220d% (8922/10000) \ntrain epoch[19/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[19/20]: 100%|██████████| 79/79 [00:09<00:00,  7.94it/s]\n\tTraining Loss: 1.039938 \tValidation Loss: 1.472405\n\tTrain Accuracy: 94.427d% (37771/40000)\tValdation Accuracy: 88.590d% (8859/10000) \ntrain epoch[20/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[20/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 1.030595 \tValidation Loss: 1.559108\n\tTrain Accuracy: 94.547d% (37819/40000)\tValdation Accuracy: 88.630d% (8863/10000) \nFinished Distilling\ntest: 100%|██████████| 79/79 [00:08<00:00,  9.08it/s]\ntest_loss: 1.664  test_accuracy: 89.220\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"T=7\nalpha=0.5\n\nprint(f\"\\n==== Training with T={T} , alpha={alpha} ====\")        \nStudent_re = resnet18(num_classes=10)\nStudent_re = Student_re.to(device)\ndistiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\ntrain_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=20, learning_rate=0.001, device=device)\n\nreS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n\nresults.append((T, alpha, reS_accuracy, reS_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T08:13:08.653576Z","iopub.execute_input":"2025-07-20T08:13:08.654088Z","iopub.status.idle":"2025-07-20T08:37:14.661344Z","shell.execute_reply.started":"2025-07-20T08:13:08.654063Z","shell.execute_reply":"2025-07-20T08:37:14.660814Z"}},"outputs":[{"name":"stdout","text":"\n==== Training with T=7 , alpha=0.5 ====\ntrain epoch[1/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[1/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 10.424395 \tValidation Loss: 8.133105\n\tTrain Accuracy: 47.595d% (19038/40000)\tValdation Accuracy: 57.480d% (5748/10000) \ntrain epoch[2/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[2/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 6.867714 \tValidation Loss: 5.345875\n\tTrain Accuracy: 66.192d% (26477/40000)\tValdation Accuracy: 70.580d% (7058/10000) \ntrain epoch[3/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[3/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 5.223835 \tValidation Loss: 4.360294\n\tTrain Accuracy: 74.218d% (29687/40000)\tValdation Accuracy: 75.570d% (7557/10000) \ntrain epoch[4/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[4/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 4.120453 \tValidation Loss: 3.715120\n\tTrain Accuracy: 79.425d% (31770/40000)\tValdation Accuracy: 78.360d% (7836/10000) \ntrain epoch[5/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[5/20]: 100%|██████████| 79/79 [00:09<00:00,  7.95it/s]\n\tTraining Loss: 3.475689 \tValidation Loss: 3.211789\n\tTrain Accuracy: 82.350d% (32940/40000)\tValdation Accuracy: 80.670d% (8067/10000) \ntrain epoch[6/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[6/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 2.972430 \tValidation Loss: 2.999926\n\tTrain Accuracy: 84.580d% (33832/40000)\tValdation Accuracy: 81.010d% (8101/10000) \ntrain epoch[7/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[7/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 2.602115 \tValidation Loss: 2.767187\n\tTrain Accuracy: 86.345d% (34538/40000)\tValdation Accuracy: 82.780d% (8278/10000) \ntrain epoch[8/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[8/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 2.323314 \tValidation Loss: 2.493089\n\tTrain Accuracy: 87.690d% (35076/40000)\tValdation Accuracy: 83.430d% (8343/10000) \ntrain epoch[9/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[9/20]: 100%|██████████| 79/79 [00:09<00:00,  8.02it/s]\n\tTraining Loss: 2.084327 \tValidation Loss: 2.492875\n\tTrain Accuracy: 89.037d% (35615/40000)\tValdation Accuracy: 84.200d% (8420/10000) \ntrain epoch[10/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[10/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 1.906638 \tValidation Loss: 2.266186\n\tTrain Accuracy: 89.918d% (35967/40000)\tValdation Accuracy: 85.180d% (8518/10000) \ntrain epoch[11/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[11/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 1.754264 \tValidation Loss: 2.025251\n\tTrain Accuracy: 90.565d% (36226/40000)\tValdation Accuracy: 86.890d% (8689/10000) \ntrain epoch[12/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[12/20]: 100%|██████████| 79/79 [00:10<00:00,  7.89it/s]\n\tTraining Loss: 1.681453 \tValidation Loss: 1.759421\n\tTrain Accuracy: 91.112d% (36445/40000)\tValdation Accuracy: 87.510d% (8751/10000) \ntrain epoch[13/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[13/20]: 100%|██████████| 79/79 [00:09<00:00,  8.04it/s]\n\tTraining Loss: 1.521073 \tValidation Loss: 1.776782\n\tTrain Accuracy: 91.965d% (36786/40000)\tValdation Accuracy: 87.330d% (8733/10000) \ntrain epoch[14/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[14/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 1.397673 \tValidation Loss: 2.083494\n\tTrain Accuracy: 92.655d% (37062/40000)\tValdation Accuracy: 86.320d% (8632/10000) \ntrain epoch[15/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[15/20]: 100%|██████████| 79/79 [00:09<00:00,  8.03it/s]\n\tTraining Loss: 1.342088 \tValidation Loss: 1.725833\n\tTrain Accuracy: 92.978d% (37191/40000)\tValdation Accuracy: 87.620d% (8762/10000) \ntrain epoch[16/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[16/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.252708 \tValidation Loss: 1.719846\n\tTrain Accuracy: 93.603d% (37441/40000)\tValdation Accuracy: 87.790d% (8779/10000) \ntrain epoch[17/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[17/20]: 100%|██████████| 79/79 [00:09<00:00,  8.04it/s]\n\tTraining Loss: 1.203896 \tValidation Loss: 1.538257\n\tTrain Accuracy: 93.825d% (37530/40000)\tValdation Accuracy: 88.600d% (8860/10000) \ntrain epoch[18/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[18/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.133186 \tValidation Loss: 1.680319\n\tTrain Accuracy: 94.265d% (37706/40000)\tValdation Accuracy: 88.510d% (8851/10000) \ntrain epoch[19/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[19/20]: 100%|██████████| 79/79 [00:09<00:00,  7.91it/s]\n\tTraining Loss: 1.063819 \tValidation Loss: 1.572474\n\tTrain Accuracy: 94.675d% (37870/40000)\tValdation Accuracy: 88.790d% (8879/10000) \ntrain epoch[20/20]: 100%|██████████| 313/313 [01:02<00:00,  5.02it/s]\nvalid epoch[20/20]: 100%|██████████| 79/79 [00:09<00:00,  7.91it/s]\n\tTraining Loss: 1.007681 \tValidation Loss: 1.590519\n\tTrain Accuracy: 95.043d% (38017/40000)\tValdation Accuracy: 88.550d% (8855/10000) \nFinished Distilling\ntest: 100%|██████████| 79/79 [00:08<00:00,  9.05it/s]\ntest_loss: 1.664  test_accuracy: 89.490\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"T=8\nalpha=0.5\n\nprint(f\"\\n==== Training with T={T} , alpha={alpha} ====\")        \nStudent_re = resnet18(num_classes=10)\nStudent_re = Student_re.to(device)\ndistiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\ntrain_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=20, learning_rate=0.001, device=device)\n\nreS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n\nresults.append((T, alpha, reS_accuracy, reS_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T08:37:14.661976Z","iopub.execute_input":"2025-07-20T08:37:14.662225Z","iopub.status.idle":"2025-07-20T09:01:24.944696Z","shell.execute_reply.started":"2025-07-20T08:37:14.662208Z","shell.execute_reply":"2025-07-20T09:01:24.944132Z"}},"outputs":[{"name":"stdout","text":"\n==== Training with T=8 , alpha=0.5 ====\ntrain epoch[1/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[1/20]: 100%|██████████| 79/79 [00:10<00:00,  7.90it/s]\n\tTraining Loss: 10.512342 \tValidation Loss: 8.423324\n\tTrain Accuracy: 46.950d% (18780/40000)\tValdation Accuracy: 55.540d% (5554/10000) \ntrain epoch[2/20]: 100%|██████████| 313/313 [01:02<00:00,  5.02it/s]\nvalid epoch[2/20]: 100%|██████████| 79/79 [00:10<00:00,  7.86it/s]\n\tTraining Loss: 7.073741 \tValidation Loss: 8.674155\n\tTrain Accuracy: 64.515d% (25806/40000)\tValdation Accuracy: 55.950d% (5595/10000) \ntrain epoch[3/20]: 100%|██████████| 313/313 [01:02<00:00,  5.02it/s]\nvalid epoch[3/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 5.418953 \tValidation Loss: 4.332942\n\tTrain Accuracy: 73.090d% (29236/40000)\tValdation Accuracy: 74.850d% (7485/10000) \ntrain epoch[4/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[4/20]: 100%|██████████| 79/79 [00:09<00:00,  7.93it/s]\n\tTraining Loss: 4.262387 \tValidation Loss: 4.230931\n\tTrain Accuracy: 78.400d% (31360/40000)\tValdation Accuracy: 76.460d% (7646/10000) \ntrain epoch[5/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[5/20]: 100%|██████████| 79/79 [00:09<00:00,  7.90it/s]\n\tTraining Loss: 3.536507 \tValidation Loss: 3.993573\n\tTrain Accuracy: 81.828d% (32731/40000)\tValdation Accuracy: 77.560d% (7756/10000) \ntrain epoch[6/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[6/20]: 100%|██████████| 79/79 [00:09<00:00,  7.95it/s]\n\tTraining Loss: 3.047671 \tValidation Loss: 2.756946\n\tTrain Accuracy: 84.108d% (33643/40000)\tValdation Accuracy: 82.880d% (8288/10000) \ntrain epoch[7/20]: 100%|██████████| 313/313 [01:02<00:00,  5.02it/s]\nvalid epoch[7/20]: 100%|██████████| 79/79 [00:09<00:00,  7.94it/s]\n\tTraining Loss: 2.675847 \tValidation Loss: 2.844776\n\tTrain Accuracy: 85.963d% (34385/40000)\tValdation Accuracy: 81.900d% (8190/10000) \ntrain epoch[8/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[8/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 2.352006 \tValidation Loss: 2.277342\n\tTrain Accuracy: 87.500d% (35000/40000)\tValdation Accuracy: 85.090d% (8509/10000) \ntrain epoch[9/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[9/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 2.138506 \tValidation Loss: 2.373018\n\tTrain Accuracy: 88.660d% (35464/40000)\tValdation Accuracy: 84.470d% (8447/10000) \ntrain epoch[10/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[10/20]: 100%|██████████| 79/79 [00:09<00:00,  8.03it/s]\n\tTraining Loss: 1.959137 \tValidation Loss: 2.006867\n\tTrain Accuracy: 89.380d% (35752/40000)\tValdation Accuracy: 85.720d% (8572/10000) \ntrain epoch[11/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[11/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 1.807391 \tValidation Loss: 2.066143\n\tTrain Accuracy: 90.245d% (36098/40000)\tValdation Accuracy: 86.020d% (8602/10000) \ntrain epoch[12/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[12/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.659846 \tValidation Loss: 2.017389\n\tTrain Accuracy: 91.103d% (36441/40000)\tValdation Accuracy: 86.560d% (8656/10000) \ntrain epoch[13/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[13/20]: 100%|██████████| 79/79 [00:09<00:00,  7.93it/s]\n\tTraining Loss: 1.528089 \tValidation Loss: 1.856492\n\tTrain Accuracy: 91.808d% (36723/40000)\tValdation Accuracy: 87.160d% (8716/10000) \ntrain epoch[14/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[14/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 1.444721 \tValidation Loss: 1.708781\n\tTrain Accuracy: 92.468d% (36987/40000)\tValdation Accuracy: 88.080d% (8808/10000) \ntrain epoch[15/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[15/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 1.359967 \tValidation Loss: 1.682455\n\tTrain Accuracy: 92.978d% (37191/40000)\tValdation Accuracy: 88.030d% (8803/10000) \ntrain epoch[16/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[16/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 1.265136 \tValidation Loss: 1.961471\n\tTrain Accuracy: 93.552d% (37421/40000)\tValdation Accuracy: 87.460d% (8746/10000) \ntrain epoch[17/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[17/20]: 100%|██████████| 79/79 [00:09<00:00,  7.95it/s]\n\tTraining Loss: 1.215577 \tValidation Loss: 1.587509\n\tTrain Accuracy: 93.770d% (37508/40000)\tValdation Accuracy: 88.710d% (8871/10000) \ntrain epoch[18/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[18/20]: 100%|██████████| 79/79 [00:09<00:00,  8.03it/s]\n\tTraining Loss: 1.155756 \tValidation Loss: 1.520368\n\tTrain Accuracy: 94.160d% (37664/40000)\tValdation Accuracy: 88.920d% (8892/10000) \ntrain epoch[19/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[19/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 1.062495 \tValidation Loss: 1.332187\n\tTrain Accuracy: 94.860d% (37944/40000)\tValdation Accuracy: 90.190d% (9019/10000) \ntrain epoch[20/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[20/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 1.048405 \tValidation Loss: 1.537425\n\tTrain Accuracy: 94.858d% (37943/40000)\tValdation Accuracy: 89.200d% (8920/10000) \nFinished Distilling\ntest: 100%|██████████| 79/79 [00:08<00:00,  9.09it/s]\ntest_loss: 1.701  test_accuracy: 89.340\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"T=8\nalpha=0.9\n\nprint(f\"\\n==== Training with T={T} , alpha={alpha} ====\")        \nStudent_re = resnet18(num_classes=10)\nStudent_re = Student_re.to(device)\ndistiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\ntrain_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=20, learning_rate=0.001, device=device)\n\nreS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n\nresults.append((T, alpha, reS_accuracy, reS_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T09:01:24.945400Z","iopub.execute_input":"2025-07-20T09:01:24.945644Z","iopub.status.idle":"2025-07-20T09:25:29.841801Z","shell.execute_reply.started":"2025-07-20T09:01:24.945623Z","shell.execute_reply":"2025-07-20T09:25:29.841079Z"}},"outputs":[{"name":"stdout","text":"\n==== Training with T=8 , alpha=0.9 ====\ntrain epoch[1/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[1/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 17.326421 \tValidation Loss: 14.365679\n\tTrain Accuracy: 44.852d% (17941/40000)\tValdation Accuracy: 53.320d% (5332/10000) \ntrain epoch[2/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[2/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 11.289367 \tValidation Loss: 10.040020\n\tTrain Accuracy: 64.058d% (25623/40000)\tValdation Accuracy: 65.010d% (6501/10000) \ntrain epoch[3/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[3/20]: 100%|██████████| 79/79 [00:09<00:00,  7.94it/s]\n\tTraining Loss: 8.550740 \tValidation Loss: 7.438584\n\tTrain Accuracy: 72.457d% (28983/40000)\tValdation Accuracy: 73.240d% (7324/10000) \ntrain epoch[4/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[4/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 6.742808 \tValidation Loss: 6.061383\n\tTrain Accuracy: 77.665d% (31066/40000)\tValdation Accuracy: 76.050d% (7605/10000) \ntrain epoch[5/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[5/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 5.592103 \tValidation Loss: 6.272321\n\tTrain Accuracy: 80.853d% (32341/40000)\tValdation Accuracy: 77.320d% (7732/10000) \ntrain epoch[6/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[6/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 4.767526 \tValidation Loss: 4.689701\n\tTrain Accuracy: 83.210d% (33284/40000)\tValdation Accuracy: 79.690d% (7969/10000) \ntrain epoch[7/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[7/20]: 100%|██████████| 79/79 [00:09<00:00,  8.07it/s]\n\tTraining Loss: 4.160838 \tValidation Loss: 4.096969\n\tTrain Accuracy: 85.073d% (34029/40000)\tValdation Accuracy: 82.920d% (8292/10000) \ntrain epoch[8/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[8/20]: 100%|██████████| 79/79 [00:09<00:00,  8.03it/s]\n\tTraining Loss: 3.697692 \tValidation Loss: 3.455387\n\tTrain Accuracy: 86.672d% (34669/40000)\tValdation Accuracy: 84.180d% (8418/10000) \ntrain epoch[9/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[9/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 3.328576 \tValidation Loss: 3.182108\n\tTrain Accuracy: 87.855d% (35142/40000)\tValdation Accuracy: 85.130d% (8513/10000) \ntrain epoch[10/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[10/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 3.064515 \tValidation Loss: 3.311932\n\tTrain Accuracy: 88.830d% (35532/40000)\tValdation Accuracy: 84.990d% (8499/10000) \ntrain epoch[11/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[11/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 2.789933 \tValidation Loss: 2.668120\n\tTrain Accuracy: 89.957d% (35983/40000)\tValdation Accuracy: 86.510d% (8651/10000) \ntrain epoch[12/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[12/20]: 100%|██████████| 79/79 [00:09<00:00,  7.91it/s]\n\tTraining Loss: 2.576755 \tValidation Loss: 2.422368\n\tTrain Accuracy: 90.457d% (36183/40000)\tValdation Accuracy: 87.240d% (8724/10000) \ntrain epoch[13/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[13/20]: 100%|██████████| 79/79 [00:09<00:00,  8.02it/s]\n\tTraining Loss: 2.428611 \tValidation Loss: 2.762241\n\tTrain Accuracy: 91.220d% (36488/40000)\tValdation Accuracy: 86.310d% (8631/10000) \ntrain epoch[14/20]: 100%|██████████| 313/313 [01:01<00:00,  5.07it/s]\nvalid epoch[14/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 2.234366 \tValidation Loss: 2.300912\n\tTrain Accuracy: 91.938d% (36775/40000)\tValdation Accuracy: 88.400d% (8840/10000) \ntrain epoch[15/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[15/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 2.066817 \tValidation Loss: 2.296329\n\tTrain Accuracy: 92.690d% (37076/40000)\tValdation Accuracy: 88.280d% (8828/10000) \ntrain epoch[16/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[16/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 1.985005 \tValidation Loss: 2.435294\n\tTrain Accuracy: 92.957d% (37183/40000)\tValdation Accuracy: 87.640d% (8764/10000) \ntrain epoch[17/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[17/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 1.870899 \tValidation Loss: 2.217109\n\tTrain Accuracy: 93.450d% (37380/40000)\tValdation Accuracy: 88.740d% (8874/10000) \ntrain epoch[18/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[18/20]: 100%|██████████| 79/79 [00:09<00:00,  8.05it/s]\n\tTraining Loss: 1.754704 \tValidation Loss: 2.201177\n\tTrain Accuracy: 94.070d% (37628/40000)\tValdation Accuracy: 88.580d% (8858/10000) \ntrain epoch[19/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[19/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.683868 \tValidation Loss: 2.077674\n\tTrain Accuracy: 94.177d% (37671/40000)\tValdation Accuracy: 89.160d% (8916/10000) \ntrain epoch[20/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[20/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.599908 \tValidation Loss: 1.935300\n\tTrain Accuracy: 94.520d% (37808/40000)\tValdation Accuracy: 89.270d% (8927/10000) \nFinished Distilling\ntest: 100%|██████████| 79/79 [00:08<00:00,  9.06it/s]\ntest_loss: 2.143  test_accuracy: 89.630\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"T=10\nalpha=0.9\n\nprint(f\"\\n==== Training with T={T} , alpha={alpha} ====\")        \nStudent_re = resnet18(num_classes=10)\nStudent_re = Student_re.to(device)\ndistiller_re = Distiller(Teacher, Student_re, type='response', T=T, alpha=alpha)\ntrain_distillation(distiller_re, Student_re, train_loader, val_loader, epochs=20, learning_rate=0.001, device=device)\n\nreS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)\n\nresults.append((T, alpha, reS_accuracy, reS_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T09:25:29.842634Z","iopub.execute_input":"2025-07-20T09:25:29.843288Z","iopub.status.idle":"2025-07-20T09:49:35.910110Z","shell.execute_reply.started":"2025-07-20T09:25:29.843269Z","shell.execute_reply":"2025-07-20T09:49:35.909563Z"}},"outputs":[{"name":"stdout","text":"\n==== Training with T=10 , alpha=0.9 ====\ntrain epoch[1/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[1/20]: 100%|██████████| 79/79 [00:09<00:00,  8.05it/s]\n\tTraining Loss: 15.979496 \tValidation Loss: 11.696926\n\tTrain Accuracy: 45.735d% (18294/40000)\tValdation Accuracy: 56.140d% (5614/10000) \ntrain epoch[2/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[2/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 10.418606 \tValidation Loss: 8.980486\n\tTrain Accuracy: 64.953d% (25981/40000)\tValdation Accuracy: 68.210d% (6821/10000) \ntrain epoch[3/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[3/20]: 100%|██████████| 79/79 [00:09<00:00,  8.04it/s]\n\tTraining Loss: 7.744990 \tValidation Loss: 6.036809\n\tTrain Accuracy: 73.715d% (29486/40000)\tValdation Accuracy: 76.050d% (7605/10000) \ntrain epoch[4/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[4/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 6.059528 \tValidation Loss: 5.780829\n\tTrain Accuracy: 78.805d% (31522/40000)\tValdation Accuracy: 76.280d% (7628/10000) \ntrain epoch[5/20]: 100%|██████████| 313/313 [01:02<00:00,  5.05it/s]\nvalid epoch[5/20]: 100%|██████████| 79/79 [00:09<00:00,  7.92it/s]\n\tTraining Loss: 5.004428 \tValidation Loss: 5.732069\n\tTrain Accuracy: 81.970d% (32788/40000)\tValdation Accuracy: 76.820d% (7682/10000) \ntrain epoch[6/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[6/20]: 100%|██████████| 79/79 [00:09<00:00,  7.97it/s]\n\tTraining Loss: 4.330306 \tValidation Loss: 4.176839\n\tTrain Accuracy: 84.028d% (33611/40000)\tValdation Accuracy: 81.400d% (8140/10000) \ntrain epoch[7/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[7/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 3.787150 \tValidation Loss: 3.870038\n\tTrain Accuracy: 85.965d% (34386/40000)\tValdation Accuracy: 81.790d% (8179/10000) \ntrain epoch[8/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[8/20]: 100%|██████████| 79/79 [00:09<00:00,  8.04it/s]\n\tTraining Loss: 3.361093 \tValidation Loss: 3.998912\n\tTrain Accuracy: 87.195d% (34878/40000)\tValdation Accuracy: 81.760d% (8176/10000) \ntrain epoch[9/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[9/20]: 100%|██████████| 79/79 [00:09<00:00,  7.93it/s]\n\tTraining Loss: 3.048727 \tValidation Loss: 3.136834\n\tTrain Accuracy: 88.368d% (35347/40000)\tValdation Accuracy: 85.700d% (8570/10000) \ntrain epoch[10/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[10/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 2.822088 \tValidation Loss: 2.792690\n\tTrain Accuracy: 89.435d% (35774/40000)\tValdation Accuracy: 86.750d% (8675/10000) \ntrain epoch[11/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[11/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 2.576275 \tValidation Loss: 2.545447\n\tTrain Accuracy: 90.377d% (36151/40000)\tValdation Accuracy: 87.380d% (8738/10000) \ntrain epoch[12/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[12/20]: 100%|██████████| 79/79 [00:09<00:00,  7.96it/s]\n\tTraining Loss: 2.408268 \tValidation Loss: 2.398590\n\tTrain Accuracy: 90.843d% (36337/40000)\tValdation Accuracy: 87.350d% (8735/10000) \ntrain epoch[13/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[13/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 2.178794 \tValidation Loss: 2.303537\n\tTrain Accuracy: 91.677d% (36671/40000)\tValdation Accuracy: 87.640d% (8764/10000) \ntrain epoch[14/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[14/20]: 100%|██████████| 79/79 [00:09<00:00,  8.00it/s]\n\tTraining Loss: 2.054830 \tValidation Loss: 2.503448\n\tTrain Accuracy: 92.230d% (36892/40000)\tValdation Accuracy: 87.800d% (8780/10000) \ntrain epoch[15/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[15/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.926249 \tValidation Loss: 2.566614\n\tTrain Accuracy: 93.115d% (37246/40000)\tValdation Accuracy: 86.940d% (8694/10000) \ntrain epoch[16/20]: 100%|██████████| 313/313 [01:01<00:00,  5.06it/s]\nvalid epoch[16/20]: 100%|██████████| 79/79 [00:09<00:00,  7.98it/s]\n\tTraining Loss: 1.854062 \tValidation Loss: 2.126000\n\tTrain Accuracy: 93.153d% (37261/40000)\tValdation Accuracy: 88.170d% (8817/10000) \ntrain epoch[17/20]: 100%|██████████| 313/313 [01:01<00:00,  5.05it/s]\nvalid epoch[17/20]: 100%|██████████| 79/79 [00:09<00:00,  8.05it/s]\n\tTraining Loss: 1.751970 \tValidation Loss: 2.065995\n\tTrain Accuracy: 93.585d% (37434/40000)\tValdation Accuracy: 88.700d% (8870/10000) \ntrain epoch[18/20]: 100%|██████████| 313/313 [01:02<00:00,  5.03it/s]\nvalid epoch[18/20]: 100%|██████████| 79/79 [00:09<00:00,  7.99it/s]\n\tTraining Loss: 1.652743 \tValidation Loss: 2.166064\n\tTrain Accuracy: 94.030d% (37612/40000)\tValdation Accuracy: 88.450d% (8845/10000) \ntrain epoch[19/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[19/20]: 100%|██████████| 79/79 [00:09<00:00,  7.91it/s]\n\tTraining Loss: 1.584450 \tValidation Loss: 2.031298\n\tTrain Accuracy: 94.360d% (37744/40000)\tValdation Accuracy: 88.950d% (8895/10000) \ntrain epoch[20/20]: 100%|██████████| 313/313 [01:02<00:00,  5.04it/s]\nvalid epoch[20/20]: 100%|██████████| 79/79 [00:09<00:00,  8.01it/s]\n\tTraining Loss: 1.495628 \tValidation Loss: 1.899510\n\tTrain Accuracy: 94.920d% (37968/40000)\tValdation Accuracy: 89.420d% (8942/10000) \nFinished Distilling\ntest: 100%|██████████| 79/79 [00:08<00:00,  9.10it/s]\ntest_loss: 2.011  test_accuracy: 90.010\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"best = max(results, key=lambda x: x[2])\nprint(f'\\nBest Group：T={best[0]}, alpha={best[1]}, accuracy={best[2]:.2f}, loss={best[3]:.2f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T09:49:35.910828Z","iopub.execute_input":"2025-07-20T09:49:35.911070Z","iopub.status.idle":"2025-07-20T09:49:35.915269Z","shell.execute_reply.started":"2025-07-20T09:49:35.911053Z","shell.execute_reply":"2025-07-20T09:49:35.914468Z"}},"outputs":[{"name":"stdout","text":"\nBest Group：T=10, alpha=0.9, accuracy=90.01, loss=2.01\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Comparison","metadata":{}},{"cell_type":"code","source":"print(f'Teacher from scratch: loss-0.482, accuracy-91.420') \nprint(f'Student from scratch: loss-0.441, accuracy-85.850')\nprint(f'Response-based student: loss-{best[3]}, accuracy-{best[2]}')","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T09:49:35.915999Z","iopub.execute_input":"2025-07-20T09:49:35.916192Z","iopub.status.idle":"2025-07-20T09:49:35.934574Z","shell.execute_reply.started":"2025-07-20T09:49:35.916178Z","shell.execute_reply":"2025-07-20T09:49:35.933872Z"}},"outputs":[{"name":"stdout","text":"Teacher from scratch: loss-0.482, accuracy-91.420\nStudent from scratch: loss-0.441, accuracy-85.850\nResponse-based student: loss-2.010814321192005, accuracy-90.01\n","output_type":"stream"}],"execution_count":23}]}